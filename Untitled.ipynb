{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "197a6d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: model.onnx\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 76\u001b[0m\n\u001b[0;32m     73\u001b[0m torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mexport(model, example_input, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m, opset_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m11\u001b[39m)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Convert the ONNX model to TensorFlow Lite format\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_saved_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     77\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m converter\u001b[38;5;241m.\u001b[39mconvert()\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Save the TensorFlow Lite model to a file\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\lite\\python\\lite.py:2012\u001b[0m, in \u001b[0;36mTFLiteConverterV2.from_saved_model\u001b[1;34m(cls, saved_model_dir, signature_keys, tags)\u001b[0m\n\u001b[0;32m   2009\u001b[0m   tags \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m([_tag_constants\u001b[38;5;241m.\u001b[39mSERVING])\n\u001b[0;32m   2011\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39meager_mode():\n\u001b[1;32m-> 2012\u001b[0m   saved_model \u001b[38;5;241m=\u001b[39m _load(saved_model_dir, tags)\n\u001b[0;32m   2013\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signature_keys:\n\u001b[0;32m   2014\u001b[0m   signature_keys \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39msignatures\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\saved_model\\load.py:858\u001b[0m, in \u001b[0;36mload\u001b[1;34m(export_dir, tags, options)\u001b[0m\n\u001b[0;32m    856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(export_dir, os\u001b[38;5;241m.\u001b[39mPathLike):\n\u001b[0;32m    857\u001b[0m   export_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(export_dir)\n\u001b[1;32m--> 858\u001b[0m result \u001b[38;5;241m=\u001b[39m load_partial(export_dir, \u001b[38;5;28;01mNone\u001b[39;00m, tags, options)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\saved_model\\load.py:963\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tags, \u001b[38;5;28mset\u001b[39m):\n\u001b[0;32m    959\u001b[0m   \u001b[38;5;66;03m# Supports e.g. tags=SERVING and tags=[SERVING]. Sets aren't considered\u001b[39;00m\n\u001b[0;32m    960\u001b[0m   \u001b[38;5;66;03m# sequences for nest.flatten, so we put those through as-is.\u001b[39;00m\n\u001b[0;32m    961\u001b[0m   tags \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mflatten(tags)\n\u001b[0;32m    962\u001b[0m saved_model_proto, debug_info \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 963\u001b[0m     loader_impl\u001b[38;5;241m.\u001b[39mparse_saved_model_with_debug_info(export_dir))\n\u001b[0;32m    965\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    966\u001b[0m     saved_model_proto\u001b[38;5;241m.\u001b[39mmeta_graphs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_graph_def\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    967\u001b[0m   metrics\u001b[38;5;241m.\u001b[39mIncrementReadApi(_LOAD_V2_LABEL)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:58\u001b[0m, in \u001b[0;36mparse_saved_model_with_debug_info\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_saved_model_with_debug_info\u001b[39m(export_dir):\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Reads the savedmodel as well as the graph debug info.\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    parsed. Missing graph debug info file is fine.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m   saved_model \u001b[38;5;241m=\u001b[39m parse_saved_model(export_dir)\n\u001b[0;32m     60\u001b[0m   debug_info_path \u001b[38;5;241m=\u001b[39m file_io\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m     61\u001b[0m       path_helpers\u001b[38;5;241m.\u001b[39mget_debug_dir(export_dir),\n\u001b[0;32m     62\u001b[0m       constants\u001b[38;5;241m.\u001b[39mDEBUG_INFO_FILENAME_PB)\n\u001b[0;32m     63\u001b[0m   debug_info \u001b[38;5;241m=\u001b[39m graph_debug_info_pb2\u001b[38;5;241m.\u001b[39mGraphDebugInfo()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py:116\u001b[0m, in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot parse file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_to_pbtxt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 116\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    117\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSavedModel file does not exist at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexport_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    118\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PBTXT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    119\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_FILENAME_PB\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: model.onnx\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.onnx\n",
    "from torchvision.models import squeezenet1_1\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the ConvNet class\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=7):\n",
    "        super(ConvNet,self).__init__()\n",
    " \n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "\n",
    "        self.relu1=nn.ReLU()\n",
    "   \n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "    \n",
    "        self.relu2=nn.ReLU()\n",
    "   \n",
    "\n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "    \n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "   \n",
    "        self.relu3=nn.ReLU()\n",
    "    \n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output=self.conv1(input)\n",
    "        output=self.bn1(output)\n",
    "        output=self.relu1(output)\n",
    "            \n",
    "        output=self.pool(output)\n",
    "            \n",
    "        output=self.conv2(output)\n",
    "        output=self.relu2(output)\n",
    "            \n",
    "        output=self.conv3(output)\n",
    "        output=self.bn3(output)\n",
    "        output=self.relu3(output)\n",
    "            \n",
    "            \n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "            \n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output\n",
    "\n",
    "# Load your trained PyTorch model\n",
    "model = ConvNet(num_classes=7)\n",
    "model.load_state_dict(torch.load('best_checkpoint.model'))\n",
    "model.eval()\n",
    "\n",
    "# Example input (adjust the shape based on your model's input size)\n",
    "example_input = torch.randn(1, 3, 150, 150)\n",
    "\n",
    "# Export the model to ONNX\n",
    "torch.onnx.export(model, example_input, 'model.onnx', opset_version=11)\n",
    "\n",
    "# Convert the ONNX model to TensorFlow Lite format\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model('model.onnx')\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "with open('model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d7113e",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
